This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  settings.local.json
src/
  tabs/
    customer_market.py
    executive_overview.py
    growth_insights.py
    product_intelligence.py
    product_launching.py
    vietnam_focus.py
  analysis.py
  charts.py
  data_processing.py
  ui_helpers.py
  utils.py
.gitignore
dashboard.py
debug_active.py
inspect_data.py
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(test:*)",
      "Bash(mkdir:*)",
      "Bash(npx repomix:*)"
    ],
    "deny": [],
    "ask": []
  }
}
</file>

<file path="src/tabs/customer_market.py">
import streamlit as st
import pandas as pd
import plotly.express as px
from src.utils import DEFAULT_DATE_COL

def render_customer_market(df, df_curr):
    c1, c2 = st.columns(2)
        
    with c1:
        st.subheader("üåç Regional Performance")
        region_stats = df_curr.groupby('Country')['Sold'].sum().reset_index().sort_values('Sold', ascending=False)
        fig_map = px.bar(region_stats, x='Sold', y='Country', orientation='h', title="Revenue by Country", text_auto=',.0f')
        fig_map.update_layout(yaxis={'categoryorder':'total ascending'}, template="plotly_white")
        st.plotly_chart(fig_map, use_container_width=True)
        
    with c2:
        st.subheader("üë• Client Segments (RFM Approximation)")
        # Very simple segmentation based on Revenue
        client_rev = df_curr.groupby('Name of client')['Sold'].sum().reset_index()
        def segment(row):
            if row['Sold'] > 50000: return 'Diamond' # arbitrary thresholds
            elif row['Sold'] > 10000: return 'Gold'
            elif row['Sold'] > 1000: return 'Silver'
            else: return 'Bronze'
        
        if not client_rev.empty:
            client_rev['Segment'] = client_rev.apply(segment, axis=1)
            seg_counts = client_rev['Segment'].value_counts().reset_index()
            seg_counts.columns = ['Segment', 'Count']
            fig_pie = px.pie(seg_counts, names='Segment', values='Count', title="Client Value Distribution", hole=0.4)
            st.plotly_chart(fig_pie, use_container_width=True)
            
            with st.expander("‚ÑπÔ∏è Segmentation Criteria"):
                st.markdown("""
                - **Diamond**: > 50,000 KG
                - **Gold**: > 10,000 KG
                - **Silver**: > 1,000 KG
                - **Bronze**: ‚â§ 1,000 KG
                """)
        else:
            st.write("No client data available.")
    
    st.subheader("üèÜ Top Clients")
    
    # Channel Filter
    avail_channels = sorted(df['Channel by Sales Person'].dropna().unique()) if 'Channel by Sales Person' in df.columns else []
    selected_channels = st.multiselect("Filter by Channel (Sales Person):", options=avail_channels, default=avail_channels)
    
    if selected_channels:
            df_clients_src = df_curr[df_curr['Channel by Sales Person'].isin(selected_channels)]
    else:
            df_clients_src = df_curr
    
    top_clients = df_clients_src.groupby('Name of client').agg(
        Total_Revenue=('Sold', 'sum'),
        Orders=('Sold', 'count'),
        Last_Order_Month=('Month', 'max')
    ).sort_values('Total_Revenue', ascending=False).head(20).reset_index()

    # --- 6-Month Gap Analysis Columns ---
    if not df.empty:
            max_d = df[DEFAULT_DATE_COL].max()
            cutoff_gap = max_d - pd.DateOffset(months=6)
            
            # Filter for 6m & Channel
            df_6m_gap = df[(df[DEFAULT_DATE_COL] >= cutoff_gap) & (df[DEFAULT_DATE_COL] <= max_d)]
            if selected_channels:
                df_6m_gap = df_6m_gap[df_6m_gap['Channel by Sales Person'].isin(selected_channels)]
            
            # Universe: All fruits sold in this period/channel per Type
            type_universe = df_6m_gap.groupby('Type of product')['Kind of fruit'].unique().apply(set).to_dict()
            
            type_col_data = []
            gap_col_data = []
            
            for client in top_clients['Name of client']:
                client_data = df_6m_gap[df_6m_gap['Name of client'] == client]
                
                if client_data.empty:
                    type_col_data.append("No 6m Data")
                    gap_col_data.append("-")
                    continue
                
                # Types
                bought_types = sorted(client_data['Type of product'].dropna().unique())
                type_str = ", ".join(bought_types)
                type_col_data.append(type_str)
                
                # Variety Gaps
                details = []
                for t in bought_types:
                    if t not in type_universe: continue
                    
                    bought_fruits = set(client_data[client_data['Type of product'] == t]['Kind of fruit'].dropna().unique())
                    all_vals = type_universe[t]
                    missing = sorted(list(all_vals - bought_fruits))
                    
                    # Format: "Puree: ‚úÖ3 ‚ùå5 (Miss: Mango...)"
                    miss_txt = ", ".join(missing[:3])
                    if len(missing) > 3: miss_txt += "..."
                    if not missing: miss_txt = "-"
                    
                    line = f"**{t}**: ‚úÖ{len(bought_fruits)} / ‚ùå{len(missing)} (Miss: {miss_txt})"
                    details.append(line)
                
                gap_col_data.append("\n".join(details))
            
            top_clients['Types of Product (6m)'] = type_col_data
            top_clients['Fruit Variety Analysis (6m)'] = gap_col_data
    
    st.dataframe(
        top_clients.style.format({"Total_Revenue": "{:,.0f}", "Orders": "{:,.0f}"}),
        column_config={
            "Total_Revenue": st.column_config.NumberColumn("Total Volume (KG)"),
            "Orders": st.column_config.NumberColumn(),
            "Types of Product (6m)": st.column_config.TextColumn(width="medium"),
            "Fruit Variety Analysis (6m)": st.column_config.TextColumn(width="large"),
        },
        use_container_width=True, 
        hide_index=True
    )
</file>

<file path="src/tabs/executive_overview.py">
import streamlit as st
import pandas as pd
import plotly.express as px
from src.utils import calculate_growth, DEFAULT_DATE_COL

def render_executive_overview(df_curr, df_prev, selected_years, selected_months, current_year_val, single_year_mode, has_prev_year):
    comp_label = "vs Prev Year" if single_year_mode and has_prev_year else ("vs Prev Month" if single_year_mode else "Multi-Year View")

    st.subheader(f"Key Performance Indicators ({comp_label if has_prev_year else 'MoM (Last Month)'})")
    
    # Calculate Metrics
    curr_rev = df_curr['Sold'].sum()
    curr_vol = df_curr['Quantity (KG)'].sum()
    curr_clients = df_curr['Name of client'].nunique()
    curr_orders = len(df_curr)
    curr_aov = curr_rev / curr_orders if curr_orders else 0
    
    # Growth Calculation
    growth_rev, growth_vol, growth_aov, growth_clients = None, None, None, None
    
    if has_prev_year:
        # YoY
        prev_rev = df_prev['Sold'].sum()
        prev_vol = df_prev['Quantity (KG)'].sum()
        prev_orders = len(df_prev)
        prev_aov = prev_rev / prev_orders if prev_orders else 0
        prev_clients = df_prev['Name of client'].nunique()
        
        growth_rev = calculate_growth(curr_rev, prev_rev)
        growth_vol = calculate_growth(curr_vol, prev_vol)
        growth_aov = calculate_growth(curr_aov, prev_aov)
        growth_clients = calculate_growth(curr_clients, prev_clients)
        
    elif not df_curr.empty:
        # Single Year / No Prev Year -> MoM Calculation (Last Month vs Month Before)
        # Aggregate by month to find latest month
        monthly_agg = df_curr.groupby('Month').agg({
            'Sold': 'sum', 
            'Quantity (KG)': 'sum',
            'Name of client': 'nunique'
        }).sort_index()
        
        # Use 'date__ym' to sort correctly if Month col is messy
        monthly_agg_t = df_curr.groupby(DEFAULT_DATE_COL).agg({
            'Sold': 'sum', 
            'Quantity (KG)': 'sum',
            'Name of client': 'nunique',
            'Month': 'count' # orders proxy
        }).sort_index()
        
        if len(monthly_agg_t) >= 2:
            last_m = monthly_agg_t.iloc[-1]
            prev_m = monthly_agg_t.iloc[-2]
            
            # Show growth of LATEST MONTH in the selection
            # Note: The Displayed "Total Revenue" is typically TOTAL for the selection.
            # Showing growth of "Total 2024" vs "Total 2023(missing)" is N/A.
            # But showing growth of "Dec" vs "Nov" implies the KPI card is for "Dec".
            # If user selected "All", Total is Year Total.
            
            # Compromise:
            # If "All" selected -> Show Total. Growth is N/A (or maybe show trend sparkline?).
            # If "Single Month" selected -> Show MoM.
            
            if selected_months and len(selected_months) == 1:
                # Valid MoM case
                prev_rev = 0 
                # Try to find prev month in full data?
                # Too complex for this snippet as we don't have full df passed just for this edge case in strict structure,
                # but we could assume df_curr is enough if we had more context. 
                # For now, pass.
                pass
    
    # Display Metrics
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Total Revenue", f"{curr_rev:,.0f}", f"{growth_rev:.1%}" if growth_rev else None)
    c2.metric("Total Volume (KG)", f"{curr_vol:,.0f}", f"{growth_vol:.1%}" if growth_vol else None)
    c3.metric("Avg Order Value", f"{curr_aov:,.0f}", f"{growth_aov:.1%}" if growth_aov else None)
    c4.metric("Active Clients", f"{curr_clients:,.0f}", f"{growth_clients:.1%}" if growth_clients else None)
    
    if not has_prev_year:
        st.caption("‚ÑπÔ∏è Previous Year data not available. Comparisons are disabled.")
    
    st.divider()
    
    # Trend Analysis
    st.subheader("Revenue Trend")
    
    if len(selected_years) > 1:
        # Multi-year selection: Distinct lines for each year
        trend_curr = df_curr.sort_values(DEFAULT_DATE_COL).groupby(['Year', 'Month'])['Sold'].sum().reset_index()
        trend_curr['Type'] = trend_curr['Year'].astype(str)
        trend_combined = trend_curr
        title_chart = "Monthly Revenue Trend (Multi-Year)"
    else:
        # Single Less selection: Aggregate by Month + Optional YoY
        def agg_monthly(d):
            d = d.sort_values(DEFAULT_DATE_COL)
            return d.groupby('Month', sort=False)['Sold'].sum().reset_index()
        
        trend_curr = agg_monthly(df_curr).assign(Type='Selected Period')
        
        if has_prev_year and not df_prev.empty:
            trend_prev = agg_monthly(df_prev).assign(Type=f'{current_year_val - 1}')
            trend_curr['Type'] = f'{current_year_val}' # Rename for clarity
            trend_combined = pd.concat([trend_curr, trend_prev])
            title_chart = "Monthly Revenue Comparison (YoY)"
        else:
            trend_combined = trend_curr
            title_chart = "Monthly Revenue Trend"
    
    # Chart Controls
    chart_type = st.radio("Chart Type", ["Bar", "Line"], horizontal=True, key="monthly_chart_type")

    if chart_type == "Bar":
        fig_trend = px.bar(
            trend_combined, 
            x='Month', 
            y='Sold', 
            color='Type', 
            barmode='group',
            color_discrete_map={f'{current_year_val}': '#1E90FF', f'{current_year_val - 1}': '#D3D3D3'} if single_year_mode else None,
            title=title_chart
        )
    else:
        fig_trend = px.line(
            trend_combined, 
            x='Month', 
            y='Sold', 
            color='Type', 
            markers=True,
            text='Sold',
            color_discrete_map={f'{current_year_val}': '#1E90FF', f'{current_year_val - 1}': '#D3D3D3'} if single_year_mode else None,
            title=title_chart
        )
        fig_trend.update_traces(textposition="top center", texttemplate="%{text:,.0f}")

    fig_trend.update_layout(xaxis_title="Month", yaxis_title="Revenue", template="plotly_white", margin=dict(l=0,r=0,t=40,b=0))
    st.plotly_chart(fig_trend, use_container_width=True)
</file>

<file path="src/tabs/growth_insights.py">
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from src.utils import filter_by_date

def render_growth_insights(df_curr, df_prev, selected_years, selected_months, current_year_val, single_year_mode, has_prev_year, df, selected_regions):
    st.subheader("üöÄ Growth Intelligence & Spike Analysis")
    
    # --- Section 1: Type of Product Analysis ---
    st.write("### 1. Product Type Performance")
    st.caption("Analyze which Product Types (e.g., FROZEN PUREE, FROZEN FRUIT) are driving volume.")
    
    # Group by Type of Product
    type_stats = df_curr.groupby('Type of product').agg(
        Volume=('Sold', 'sum'),
        Kind_Count=('Kind of fruit', 'nunique')
    ).reset_index().sort_values('Volume', ascending=False)
    
    c_type1, c_type2 = st.columns([1, 2])
    
    with c_type1:
        st.dataframe(
            type_stats.style.format({"Volume": "{:,.0f}"}), 
            column_config={
                "Volume": st.column_config.NumberColumn(),
                "Kind_Count": st.column_config.NumberColumn("Fruit Varieties", help="Number of distinct fruits"),
            },
            hide_index=True,
            use_container_width=True
        )
        
    with c_type2:
        # Trend by Type
        # Filter top 5 types to avoid clutter
        top_types = type_stats.head(5)['Type of product'].tolist()
        # df_curr is full data
        df_type_trend = df_curr[df_curr['Type of product'].isin(top_types)].copy()
        
        # Multi-Year Logic
        if len(selected_years) > 1:
            df_type_trend['Label'] = df_type_trend['Type of product'] + " (" + df_type_trend['Year'].astype(str) + ")"
            type_trend = df_type_trend.groupby(['Year', 'Month', 'Type of product', 'Label'])['Sold'].sum().reset_index()
            color_col = 'Label'
        else:
            type_trend = df_type_trend.groupby(['Month', 'Type of product'])['Sold'].sum().reset_index()
            color_col = 'Type of product'
        
        # Ensure sorting for line chart
        type_trend = type_trend.sort_values(['Month'])
        
        fig_type = px.line(
            type_trend, x='Month', y='Sold', color=color_col, 
            title='Monthly Trend by Top Product Types', markers=True,
            text='Sold'
        )
        fig_type.update_traces(textposition="top center", texttemplate="%{text:,.0f}")
        st.plotly_chart(fig_type, use_container_width=True)

    st.divider()

    # --- Section 2: Spike Detection ---
    st.write("### 2. Spike Detection (Growth > 30%)")
    st.caption("Identify SKUs that surged in volume compared to the previous period and see WHO bought them.")
    
    spike_df = pd.DataFrame()
    
    # single_year_mode passed as arg
    if not single_year_mode:
        st.warning("‚ö†Ô∏è Spike detection requires a Single Year selection to perform clear Period-over-Period comparison.")
    else:
        c_ctrl1, c_ctrl2 = st.columns([1, 2])
        with c_ctrl1:
            spike_mode = st.radio("Compare vs:", ["Previous Year (YoY)", "Previous Month (MoM)"], horizontal=True)
        with c_ctrl2:
            # Add Min Volume Threshold
            min_vol = st.number_input("Ignore Spikes with Current Volume < (KG):", min_value=0, value=50, step=10)
        
        baseline_df = pd.DataFrame()
        # current_year_val passed
        
        error_msg = None

        if spike_mode == "Previous Year (YoY)":
            years_in_data = df['Year'].unique()
            prev_yr = current_year_val - 1
            if prev_yr in years_in_data:
                baseline_df = filter_by_date(df, [prev_yr], selected_months)
                baseline_df = baseline_df[baseline_df['Region'].isin(selected_regions)]
            else:
                error_msg = "No Previous Year data available for YoY comparison."
        else: # MoM
            all_months = sorted(df['Month'].dropna().unique())
            # Logic: If 1 month selected (e.g. 5), baseline is month 4.
            if selected_months and len(selected_months) == 1:
                    try:
                        # Assume selected_months has values matching 'Month' col which should be INTs now due to cleaning
                        curr_m_val = selected_months[0]
                        # Find prev value in all_months list
                        if curr_m_val in all_months:
                            idx = list(all_months).index(curr_m_val)
                            if idx > 0:
                                prev_m_val = all_months[idx - 1]
                                baseline_df = filter_by_date(df, [current_year_val], [prev_m_val])
                                baseline_df = baseline_df[baseline_df['Region'].isin(selected_regions)]
                            else:
                                error_msg = "Selected month is the first available. Cannot compare to previous."
                    except Exception as e:
                        error_msg = f"Error determining previous month: {e}"
            else:
                error_msg = "For MoM Spike detection, please select exactly ONE month in the sidebar."

        if error_msg:
            st.warning(f"‚ö†Ô∏è {error_msg}")
        
        elif not baseline_df.empty:
            # Calculate Growth per SKU
            curr_sku = df_curr.groupby(['SKU', 'Name of product'])['Sold'].sum().reset_index().rename(columns={'Sold': 'Curr_Vol'})
            base_sku = baseline_df.groupby(['SKU', 'Name of product'])['Sold'].sum().reset_index().rename(columns={'Sold': 'Base_Vol'})
            
            merged = pd.merge(curr_sku, base_sku, on=['SKU', 'Name of product'], how='left').fillna(0)
            
            merged['Growth_Pct'] = (merged['Curr_Vol'] - merged['Base_Vol']) / merged['Base_Vol']
            # Clean up infinite/NaN
            merged['Growth_Pct'] = merged['Growth_Pct'].replace([np.inf, -np.inf], 0).fillna(0) 
                # Logic adjustment: If Base is 0 and Curr > 0, growth is Infinite ideally, 
                # but technically undefined numerator relative to 0. 
                # Let's handle: if Base=0 & Curr>0 => New Listing or Re-introduction.
                # Let's treat as High Growth (1.0 or 100% just for sorting)?
                # Actually, let's mark as 100% (1.0) if base is 0. 
            mask_new = (merged['Base_Vol'] == 0) & (merged['Curr_Vol'] > 0)
            merged.loc[mask_new, 'Growth_Pct'] = 1.0 # Treat as 100% growth for sorting
            
            # Threshold > 30% AND Min Volume
            spikes = merged[
                (merged['Growth_Pct'] > 0.3) & 
                (merged['Curr_Vol'] >= min_vol)
            ].sort_values('Growth_Pct', ascending=False)
            
            if spikes.empty:
                st.success(f"No SKUs with >30% growth (and >{min_vol}kg) found ({spike_mode}).")
            else:
                st.success(f"Found {len(spikes)} SKUs with >30% growth!")
                
                # 1. Select SKU
                sku_labels = spikes.apply(
                    lambda x: f"{x['Name of product']} (SKU: {x['SKU']}) | +{x['Growth_Pct']:.1%} ({x['Base_Vol']:,.0f}kg ‚û°Ô∏è {x['Curr_Vol']:,.0f}kg)", 
                    axis=1
                ).tolist()
                selected_spike_label = st.selectbox("Select SKU to Analyze:", options=sku_labels)
                
                if selected_spike_label:
                    # Extract SKU
                    import re
                    match = re.search(r'SKU:\s*(\d+)', selected_spike_label)
                    if match:
                        sel_sku_id = int(match.group(1))
                        
                        # 2. Drill Down
                        st.markdown(f"**Recall: Who bought this SKU?**")
                        
                        # Filter Main DF for this SKU in Current Period
                        # Cast sel_sku_id to string because SKU col is cleaned as string
                        sku_sales = df_curr[df_curr['SKU'] == str(sel_sku_id)]
                        
                        client_contrib = sku_sales.groupby('Name of client')['Sold'].sum().reset_index().sort_values('Sold', ascending=False)
                        total_sku_vol = client_contrib['Sold'].sum()
                        client_contrib['Share'] = client_contrib['Sold'] / total_sku_vol if total_sku_vol else 0
                        
                        st.dataframe(
                            client_contrib.head(10).style.format({"Sold": "{:,.1f}"}),
                            column_config={
                                "Sold": st.column_config.NumberColumn("Volume (KG)"),
                                "Share": st.column_config.ProgressColumn(format="%.1f%%", min_value=0, max_value=1)
                            },
                            hide_index=True,
                            use_container_width=True
                        )

    st.divider()

    # --- Section 3: Advanced YoY Dynamics ---
    st.write("### 3. Advanced YoY Dynamics")
    st.caption("Detailed Comparison: Current Year vs Previous Year (requires single previous year data).")
    
    if not has_prev_year:
            st.info("‚ÑπÔ∏è Please select a Single Year that has a Previous Year available in the data to unlock YoY Dynamics.")
    else:
        # Helper to render the analysis for a given dataframe subset
        def render_yoy_analysis_helper(d_curr, d_prev, label_suffix):
            if d_curr.empty and d_prev.empty:
                st.write("No data available for this category.")
                return

            # 3.1 Fruit Performance Matrix
            st.markdown(f"#### üçé Kind of Fruit ({label_suffix}): {current_year_val} vs {current_year_val - 1}")
            
            # Curr Agg
            fruit_curr = d_curr.groupby('Kind of fruit').agg(
                Vol_Curr=('Sold', 'sum'),
                Clients_Curr=('Name of client', 'nunique')
            ).reset_index()
            
            # Prev Agg
            fruit_prev = d_prev.groupby('Kind of fruit')['Sold'].sum().reset_index().rename(columns={'Sold': 'Vol_Prev'})
            
            # Merge
            fruit_yoy = pd.merge(fruit_curr, fruit_prev, on='Kind of fruit', how='outer').fillna(0)
            
            fruit_yoy['Delta'] = fruit_yoy['Vol_Curr'] - fruit_yoy['Vol_Prev']
            fruit_yoy['Growth %'] = (fruit_yoy['Delta'] / fruit_yoy['Vol_Prev']).replace([np.inf, -np.inf], 0).fillna(0)
            
            # Handle Infinite growth where Vol_Prev = 0 and Vol_Curr > 0
            new_fruit_mask = (fruit_yoy['Vol_Prev'] == 0) & (fruit_yoy['Vol_Curr'] > 0)
            fruit_yoy.loc[new_fruit_mask, 'Growth %'] = 1.0 
            
            # Sort by Delta Descending (Winners first)
            fruit_yoy = fruit_yoy.sort_values('Delta', ascending=False)
            
            def color_delta(val):
                color = '#d4edda' if val > 0 else '#f8d7da' if val < 0 else ''
                return f'background-color: {color}; color: black'

            st.dataframe(
                fruit_yoy.style.format({
                    "Vol_Curr": "{:,.0f}",
                    "Vol_Prev": "{:,.0f}",
                    "Delta": "{:+,.0f}",
                    "Growth %": "{:+.1%}",
                    "Clients_Curr": "{:,.0f}"
                }).map(color_delta, subset=['Delta']),
                column_config={
                    "Kind of fruit": "Fruit Variety",
                    "Vol_Curr": f"Vol {current_year_val}",
                    "Vol_Prev": f"Vol {current_year_val - 1}",
                    "Clients_Curr": "Active Clients (Curr)"
                },
                use_container_width=True,
                hide_index=True
            )
            
            # 3.2 Monthly Spike Drivers (>20% YoY)
            st.markdown(f"#### ‚ö° Monthly Trend Drivers ({label_suffix})")
            st.caption(f"Analyzing months in **{current_year_val}** with **>20% YoY Growth** caused by New vs Existing Clients.")
            
            with st.expander("‚ÑπÔ∏è Method Definitions"):
                st.markdown("""
                - **New Clients**: Clients with sales in the current month but NO sales in the same month last year.
                - **Lost Clients**: Clients with sales in the same month last year but NO sales in the current month.
                - **Existing Clients**: Clients with sales in BOTH periods. Only the *change* in volume (Current - Previous) is shown.
                """)
            
            # --- Specific Fruit Filter for this Section ---
            avail_fruits_yoy = sorted(d_curr['Kind of fruit'].dropna().unique())
            sel_fruits_yoy = st.multiselect(f"Filter Fruit Variety ({label_suffix}):", options=avail_fruits_yoy, default=avail_fruits_yoy)
            
            if not sel_fruits_yoy:
                    st.warning("Please select at least one Fruit Variety.")
            else:
                # Apply Filter
                d_curr_f = d_curr[d_curr['Kind of fruit'].isin(sel_fruits_yoy)]
                d_prev_f = d_prev[d_prev['Kind of fruit'].isin(sel_fruits_yoy)] if not d_prev.empty else d_prev
                
                # 1. Identify Months
                m_curr = d_curr_f.groupby('Month')['Sold'].sum().reset_index().rename(columns={'Sold': 'Vol_Curr'})
                m_prev = d_prev_f.groupby('Month')['Sold'].sum().reset_index().rename(columns={'Sold': 'Vol_Prev'})
                
                if not m_prev.empty:
                    m_merged = pd.merge(m_curr, m_prev, on='Month', how='inner') 
                    m_merged['Growth'] = (m_merged['Vol_Curr'] - m_merged['Vol_Prev']) / m_merged['Vol_Prev']
                else:
                    m_merged = m_curr.copy()
                    m_merged['Vol_Prev'] = 0
                    m_merged['Growth'] = 1.0 # 100% growth if no prev
            
                
                spike_months = m_merged[m_merged['Growth'] > 0.20]['Month'].tolist()
                
                if not spike_months:
                    st.info("No months found with >20% YoY growth.")
                else:
                    # Tabs for each month
                    m_tabs = st.tabs([f"Month {m}" for m in spike_months])
                    
                    for tab, m in zip(m_tabs, spike_months):
                        with tab:
                            # Driver Analysis Logic
                            d_c = d_curr_f[d_curr_f['Month'] == m]
                            d_p = d_prev_f[d_prev_f['Month'] == m]
                            
                            clients_c = set(d_c['Name of client'].unique())
                            clients_p = set(d_p['Name of client'].unique())
                            
                            new_clients = clients_c - clients_p
                            lost_clients = clients_p - clients_c
                            existing_clients = clients_c.intersection(clients_p)
                            
                            # Volumes
                            vol_new = d_c[d_c['Name of client'].isin(new_clients)]['Sold'].sum()
                            vol_lost = d_p[d_p['Name of client'].isin(lost_clients)]['Sold'].sum()
                            
                            # Existing Expansion/Contraction
                            vol_ex_prev = d_p[d_p['Name of client'].isin(existing_clients)]['Sold'].sum()
                            vol_ex_curr = d_c[d_c['Name of client'].isin(existing_clients)]['Sold'].sum()
                            vol_existing_delta = vol_ex_curr - vol_ex_prev
                            
                            total_delta = d_c['Sold'].sum() - d_p['Sold'].sum()
                            
                            bridge_data = pd.DataFrame([
                                {"Factor": "New Clients", "Impact (KG)": vol_new, "Type": "Positive"},
                                {"Factor": "Existing Clients (Expansion)", "Impact (KG)": vol_existing_delta, "Type": "Positive" if vol_existing_delta >=0 else "Negative"},
                                {"Factor": "Lost Clients", "Impact (KG)": -vol_lost, "Type": "Negative"}
                            ])
                            
                            fig_bridge = px.bar(
                                bridge_data, x="Factor", y="Impact (KG)", color="Type", 
                                text="Impact (KG)",
                                color_discrete_map={"Positive": "green", "Negative": "red"},
                                title=f"YoY Growth Drivers: Month {m}"
                            )

                            fig_bridge.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
                            st.plotly_chart(fig_bridge, use_container_width=True)
                            
                            st.markdown(f"**Total Net Increase:** {total_delta:+,.0f} KG")
                            
                            # --- Display Detailed Client Lists ---
                            st.markdown("#### üìã Client Detail Lists")
                            c_d1, c_d2, c_d3 = st.columns(3)
                            
                            with c_d1:
                                st.markdown("**üÜï New Clients**")
                                if new_clients:
                                    # New Clients: Show Current Volume
                                    df_new = d_c[d_c['Name of client'].isin(new_clients)].groupby('Name of client')['Sold'].sum().reset_index().sort_values('Sold', ascending=False)
                                    st.dataframe(
                                        df_new.style.format({"Sold": "{:,.0f}"}),
                                        column_config={
                                            "Name of client": "Client",
                                            "Sold": st.column_config.NumberColumn("Vol (Curr)")
                                        },
                                        use_container_width=True,
                                        hide_index=True
                                    )
                                else:
                                    st.caption("No new clients.")

                            with c_d2:
                                st.markdown("**üîª Lost Clients**")
                                if lost_clients:
                                    # Lost Clients: Show Previous Volume (what was lost)
                                    df_lost = d_p[d_p['Name of client'].isin(lost_clients)].groupby('Name of client')['Sold'].sum().reset_index().sort_values('Sold', ascending=False)
                                    st.dataframe(
                                        df_lost.style.format({"Sold": "{:,.0f}"}),
                                        column_config={
                                            "Name of client": "Client",
                                            "Sold": st.column_config.NumberColumn("Vol (Prev)")
                                        },
                                        use_container_width=True,
                                        hide_index=True
                                    )
                                else:
                                    st.caption("No lost clients.")
                            
                            with c_d3:
                                st.markdown("**üîÑ Existing Clients**")
                                if existing_clients:
                                    # Existing: Show Delta
                                    e_curr = d_c[d_c['Name of client'].isin(existing_clients)].groupby('Name of client')['Sold'].sum()
                                    e_prev = d_p[d_p['Name of client'].isin(existing_clients)].groupby('Name of client')['Sold'].sum()
                                    
                                    df_ex = pd.DataFrame({'Vol_Curr': e_curr, 'Vol_Prev': e_prev}).fillna(0)
                                    df_ex['Delta'] = df_ex['Vol_Curr'] - df_ex['Vol_Prev']
                                    df_ex = df_ex.sort_values('Delta', ascending=False).reset_index()
                                    
                                    def color_delta_ex(val):
                                        color = '#d4edda' if val > 0 else '#f8d7da' if val < 0 else ''
                                        return f'background-color: {color}; color: black'

                                    st.dataframe(
                                        df_ex.style.format({
                                            "Vol_Curr": "{:,.0f}",
                                            "Vol_Prev": "{:,.0f}",
                                            "Delta": "{:+,.0f}"
                                        }).map(color_delta_ex, subset=['Delta']),
                                        column_config={
                                            "Name of client": "Client",
                                            "Vol_Curr": "Curr",
                                            "Vol_Prev": "Prev",
                                            "Delta": "Change"
                                        },
                                        use_container_width=True,
                                        hide_index=True
                                    )
                                else:
                                    st.caption("No existing clients.")

        # Create Selection for Product Types (User requested Dropdown instead of Tabs)
        avail_types = sorted(df_curr['Type of product'].dropna().unique())
        
        if not avail_types:
            st.warning("No Product Types found in current data.")
        else:
            p_type = st.selectbox("Select Product Type for YoY Analysis:", avail_types)
            
            # Filter Data for this specific Type
            mask_curr = df_curr['Type of product'] == p_type
            d_type_curr = df_curr[mask_curr]
            
            if not df_prev.empty:
                mask_prev = df_prev['Type of product'] == p_type
                d_type_prev = df_prev[mask_prev]
            else:
                d_type_prev = pd.DataFrame(columns=df_curr.columns)
                
            render_yoy_analysis_helper(d_type_curr, d_type_prev, p_type)
</file>

<file path="src/tabs/product_intelligence.py">
import streamlit as st
import pandas as pd
import plotly.express as px

def render_product_intelligence(df_curr, selected_years):
    st.subheader("üì¶ Product Performance Analysis")
    
    # 1. Advanced Product Table
    prod_stats = df_curr.groupby(['Name of product', 'SKU']).agg(
        Revenue=('Sold', 'sum'),
        Volume=('Quantity (KG)', 'sum'),
        Orders=('Sold', 'count')
    ).reset_index()
    
    # Add contribution %
    total_rev = prod_stats['Revenue'].sum()
    prod_stats['Contribution'] = prod_stats['Revenue'] / total_rev if total_rev else 0
    prod_stats = prod_stats.sort_values('Revenue', ascending=False)
    
    st.dataframe(
        prod_stats.style.format({"Revenue": "{:,.0f}", "Volume": "{:,.0f}"}),
        column_config={
            "Revenue": st.column_config.NumberColumn(),
            "Volume": st.column_config.NumberColumn(format="%f KG"), 
            "Contribution": st.column_config.ProgressColumn(
                format="%.1f%%",
                min_value=0,
                max_value=1
            ),
        },
        use_container_width=True,
        hide_index=True
    )
    
    st.divider()
    
    # 2. Comparator Tool
    st.subheader("üìà Product Comparison Tool")
    st.caption("Select products to compare their performance over time.")
    
    top_products = prod_stats.head(10)['Name of product'].tolist()
    selected_prods = st.multiselect("Choose Products to Compare", options=sorted(df_curr['Name of product'].unique()), default=top_products[:2] if len(top_products)>=2 else top_products)
    
    if selected_prods:
        # Filter
        df_comp = df_curr[df_curr['Name of product'].isin(selected_prods)].copy()
        
        # Multi-year Logic
        if len(selected_years) > 1:
            df_comp['Label'] = df_comp['Name of product'] + " (" + df_comp['Year'].astype(str) + ")"
            comp_trend = df_comp.groupby(['Year', 'Month', 'Name of product', 'Label'])['Sold'].sum().reset_index()
            color_col = 'Label'
        else:
            comp_trend = df_comp.groupby(['Month', 'Name of product'])['Sold'].sum().reset_index()
            color_col = 'Name of product'
        
        fig_comp = px.line(
            comp_trend, 
            x='Month', 
            y='Sold', 
            color=color_col, 
            markers=True,
            text='Sold',
            title="Revenue Comparison Trend"
        )
        fig_comp.update_traces(textposition="top center", texttemplate="%{text:,.0f}")
        fig_comp.update_layout(template="plotly_white")
        st.plotly_chart(fig_comp, use_container_width=True)
    else:
        st.info("Select products to compare.")

    # --- Section 3: Performance by Product Type ---
    st.subheader("üìä Performance by Type")
</file>

<file path="src/tabs/product_launching.py">
import streamlit as st
import pandas as pd
import plotly.express as px
from src.utils import DEFAULT_DATE_COL

def render_product_launching(df, df_curr, df_prev, current_year_val):
    st.subheader("üöÄ Product Launching Analysis")
    
    # User Feedback: Multi-select checkboxes + Apply button
    # Using st.form to batch updates
    with st.form("launch_form"):
        c_filt1, c_filt2 = st.columns(2)
        with c_filt1:
            # Use global df for stable options
            avail_types = sorted(df['Type of product'].dropna().unique()) if 'Type of product' in df.columns else []
            sel_types_launch = st.multiselect("Filter Type of Product:", options=avail_types, key="launch_filter_type")
            
        with c_filt2:
            # Show ALL Kinds to avoid dependency issues inside form
            avail_kinds = sorted(df['Kind of fruit'].dropna().unique()) if 'Kind of fruit' in df.columns else []
            sel_kinds_launch = st.multiselect("Filter Kind of Fruit:", options=avail_kinds, key="launch_filter_kind")
        
        st.form_submit_button("Run Analysis")

    if df_curr.empty:
        st.warning("No data for current selection.")
    else:
        # Logic: Identify Products Launched in this Year (First sale date in this Year)
        
        # Start with all in current
        df_potential = df_curr.copy()
        
        # Apply Filters
        if sel_types_launch:
            df_potential = df_potential[df_potential['Type of product'].isin(sel_types_launch)]
        if sel_kinds_launch:
            df_potential = df_potential[df_potential['Kind of fruit'].isin(sel_kinds_launch)]
        
        # Identify "Launched" (New)
        curr_prods = set(df_potential['Name of product'].unique())
        num_kinds = df_potential['Kind of fruit'].nunique()
        
        # If we have previous year data, determine which are new
        launched_prods = set()
        if not df_prev.empty:
            prev_prods = set(df_prev['Name of product'].unique())
            launched_prods = curr_prods - prev_prods
            launch_msg = f"Showing {len(curr_prods)} products ({num_kinds} Fruit Varieties). Found {len(launched_prods)} NEW products (not sold in {current_year_val - 1})."
        else:
            launched_prods = curr_prods # All considered new/launch if no prev data
            launch_msg = f"Showing {len(curr_prods)} products ({num_kinds} Fruit Varieties). (No previous year for comparison)."
        
        st.success(launch_msg)
        
        # USE ALL Products for analysis, not just launched
        df_launch = df_potential.copy()
            
        # --- 1. Launching Table ---

        # --- Dialog Function (Defined once) ---
        @st.dialog("Active Customers Details")
        def show_active_customers(type_cv, kind_cv=None):
            st.write(f"**Product Type:** {type_cv}")
            if kind_cv:
                st.write(f"**Kind:** {kind_cv}")
            
            # Re-calculate active list for this specific selection
            
            # 1. Broad Filter 6m
            if not df_launch.empty:
                max_d = df_launch[DEFAULT_DATE_COL].max()
            else:
                max_d = df[DEFAULT_DATE_COL].max()
            cutoff = max_d - pd.DateOffset(months=6)
            
            d_6m = df[(df[DEFAULT_DATE_COL] >= cutoff) & (df[DEFAULT_DATE_COL] <= max_d)]
            
            # 2. Specific Filter
            if kind_cv:
                mask = (d_6m['Type of product'] == type_cv) & (d_6m['Kind of fruit'] == kind_cv)
            else:
                mask = (d_6m['Type of product'] == type_cv)
            
            d_target = d_6m[mask]
            
            if d_target.empty:
                st.warning("No data found for this period.")
                return

            # 3. Group by Client
            stats = d_target.groupby('Name of client').agg(
                Total_Orders=('Name of client', 'count'),
                Total_Vol=('Sold', 'sum'),
                Last_Order=(DEFAULT_DATE_COL, 'max')
            ).reset_index()
            
            # 4. Filter Active (>= 2 orders)
            active_stats = stats[stats['Total_Orders'] >= 2].sort_values('Total_Vol', ascending=False)
            
            if active_stats.empty:
                    st.info("No active customers (>= 2 orders) found.")
            else:
                    st.write(f"Found **{len(active_stats)}** active customers (>= 2 orders in last 6 months).")
                    st.dataframe(
                        active_stats.style.format({
                            "Total_Vol": "{:,.1f}",
                            "Last_Order": "{:%Y-%m-%d}"
                        }),
                        column_config={
                            "Name of client": "Customer",
                            "Total_Orders": "Orders",
                            "Total_Vol": "Vol (KG)",
                            "Last_Order": "Last Purchase"
                        },
                        use_container_width=True,
                        hide_index=True
                    )

        # Custom Gradient
        def highlight_total(s):
            return ['background-color: #f0fdf4; color: #166534; font-weight: bold'] * len(s)

        def custom_greens(s):
            if s.empty: return [''] * len(s)
            s_num = pd.to_numeric(s, errors='coerce').fillna(0)
            min_val = s_num.min()
            max_val = s_num.max()
            rng = max_val - min_val if max_val != min_val else 1
            colors = []
            for val in s_num:
                norm = (val - min_val) / rng
                alpha = 0.1 + (0.9 * norm)
                colors.append(f'background-color: rgba(40, 167, 69, {alpha:.2f}); color: black')
            return colors

        # Optional Checkbox for Grouping
        group_by_type = st.checkbox("Group by Type of Product", value=True, key="launch_group_type")
        group_by_kind = st.checkbox("Group by Kind of Fruit", value=True, key="launch_group_fruit")
        
        # --- Global Totals for "Total Row" Resolution ---
        if not df_launch.empty:
            max_d_global = df_launch[DEFAULT_DATE_COL].max()
        else:
            max_d_global = df[DEFAULT_DATE_COL].max()
        cutoff_global = max_d_global - pd.DateOffset(months=6)
        
        # Global 6m History (Unfiltered by Region, but time-bound)
        df_6m_raw = df[(df[DEFAULT_DATE_COL] >= cutoff_global) & (df[DEFAULT_DATE_COL] <= max_d_global)]
        
        # 1. Total Row Calculation
        df_6m_context = df_6m_raw.copy()
        if sel_types_launch:
            df_6m_context = df_6m_context[df_6m_context['Type of product'].isin(sel_types_launch)]
        if sel_kinds_launch:
            df_6m_context = df_6m_context[df_6m_context['Kind of fruit'].isin(sel_kinds_launch)]
            
        # Identify Clients who are Active (>=2 orders) in this context
        client_order_counts = df_6m_context.groupby('Name of client').size()
        global_active_clients = set(client_order_counts[client_order_counts >= 2].index)
        
        # Current View Clients
        current_clients = set(df_launch['Name of client'].unique())
        
        # Intersection
        global_unique_cust = len(current_clients)
        global_active_cust = len(current_clients & global_active_clients)
        
        
        # --- Dynamic Region Pivot ---
        if group_by_type:
            # --- C. Type Level (Broadest) ---
            
            region_pivot = df_launch.pivot_table(index=['Type of product'], 
                                                    columns='Region', 
                                                    values='Sold', 
                                                    aggfunc='sum', 
                                                    fill_value=0).reset_index()
            
            region_cols = [c for c in region_pivot.columns if c != 'Type of product']
            
            cust_counts = df_launch.groupby(['Type of product'])['Name of client'].nunique().reset_index().rename(columns={'Name of client': 'Number of customers'})
            
            launch_clients_type = df_launch[['Type of product', 'Name of client']].drop_duplicates()
            
            target_types = df_launch['Type of product'].unique()
            df_6m_type = df_6m_raw[df_6m_raw['Type of product'].isin(target_types)]
            
            type_client_counts = df_6m_type.groupby(['Type of product', 'Name of client']).size().reset_index(name='PriorOrders')
            active_pairs = type_client_counts[type_client_counts['PriorOrders'] >= 2]
            
            active_in_view = pd.merge(launch_clients_type, active_pairs, on=['Type of product', 'Name of client'], how='inner')
            
            active_counts = active_in_view.groupby('Type of product')['Name of client'].nunique().reset_index().rename(columns={'Name of client': 'Active Customers'})
            
            counts_merged = pd.merge(cust_counts, active_counts, on='Type of product', how='left')
            counts_merged['Active Customers'] = counts_merged['Active Customers'].fillna(0).astype(int)
            
            final_table = pd.merge(region_pivot, counts_merged, on=['Type of product'], how='left')
            
            final_table['Total'] = final_table[region_cols].sum(axis=1)
            
            cols_order = ['Type of product'] + sorted(region_cols) + ['Total', 'Number of customers', 'Active Customers']
            final_table = final_table[cols_order].sort_values('Total', ascending=False).reset_index(drop=True)
            
            st.caption("Select a row to view Active Customers details.")
            
            numeric_cols = region_cols + ['Total', 'Number of customers', 'Active Customers']
            
            event = st.dataframe(
                final_table.style.format("{:,.0f}", subset=numeric_cols).apply(highlight_total, subset=['Total']),
                column_config={
                    "Name of client": "Customer",
                },
                use_container_width=True,
                hide_index=True,
                on_select="rerun",
                selection_mode="single-row"
            )
            
            if event.selection.rows:
                idx = event.selection.rows[0]
                selected_row = final_table.iloc[idx]
                show_active_customers(selected_row['Type of product'], None)

            # Total Row
            sum_cols = region_cols + ['Total']
            total_values = final_table[sum_cols].sum()
            
            full_sum_cols = sum_cols + ['Number of customers', 'Active Customers']
            total_data = {c: total_values[c] for c in sum_cols}
            total_data['Type of product'] = 'TOTAL'
            total_data['Number of customers'] = global_unique_cust
            total_data['Active Customers'] = global_active_cust
            
            total_row = pd.DataFrame([total_data])
            total_row = total_row[cols_order]
            
            st.dataframe(
                total_row.style.format("{:,.0f}", subset=full_sum_cols).apply(highlight_total, subset=['Total']),
                use_container_width=True,
                hide_index=True
            )


        elif group_by_kind:
                # --- B. Kind Level (Grouped) ---
                
            region_pivot = df_launch.pivot_table(index=['Type of product', 'Kind of fruit'], 
                                                    columns='Region', 
                                                    values='Sold', 
                                                    aggfunc='sum', 
                                                    fill_value=0).reset_index()
            
            region_cols = [c for c in region_pivot.columns if c not in ['Type of product', 'Kind of fruit']]
            
            cust_counts = df_launch.groupby(['Type of product', 'Kind of fruit'])['Name of client'].nunique().reset_index().rename(columns={'Name of client': 'Number of customers'})
            
            launch_clients_kind = df_launch[['Type of product', 'Kind of fruit', 'Name of client']].drop_duplicates()
            
            target_keys = df_launch[['Type of product', 'Kind of fruit']].drop_duplicates()
            df_6m_kind = pd.merge(df_6m_raw, target_keys, on=['Type of product', 'Kind of fruit'], how='inner')
            
            kind_client_counts = df_6m_kind.groupby(['Type of product', 'Kind of fruit', 'Name of client']).size().reset_index(name='PriorOrders')
            active_pairs_kind = kind_client_counts[kind_client_counts['PriorOrders'] >= 2]
            
            active_in_view = pd.merge(launch_clients_kind, active_pairs_kind, on=['Type of product', 'Kind of fruit', 'Name of client'], how='inner')
            active_counts = active_in_view.groupby(['Type of product', 'Kind of fruit'])['Name of client'].nunique().reset_index().rename(columns={'Name of client': 'Active Customers'})
            
            counts_merged = pd.merge(cust_counts, active_counts, on=['Type of product', 'Kind of fruit'], how='left')
            counts_merged['Active Customers'] = counts_merged['Active Customers'].fillna(0).astype(int)
            
            final_table = pd.merge(region_pivot, counts_merged, on=['Type of product', 'Kind of fruit'], how='left')
            final_table['Total'] = final_table[region_cols].sum(axis=1)
            
            cols_order = ['Type of product', 'Kind of fruit'] + sorted(region_cols) + ['Total', 'Number of customers', 'Active Customers']
            final_table = final_table[cols_order].sort_values('Total', ascending=False).reset_index(drop=True)
            
            st.caption("Select a row to view Active Customers details.")
            
            numeric_cols = region_cols + ['Total', 'Number of customers', 'Active Customers']
            
            event = st.dataframe(
                final_table.style.format("{:,.0f}", subset=numeric_cols).apply(highlight_total, subset=['Total']),
                use_container_width=True,
                hide_index=True,
                on_select="rerun",
                selection_mode="single-row"
            )
            
            if event.selection.rows:
                idx = event.selection.rows[0]
                selected_row = final_table.iloc[idx]
                show_active_customers(selected_row['Type of product'], selected_row['Kind of fruit'])
            
            # Total Row
            sum_cols = region_cols + ['Total']
            total_values = final_table[sum_cols].sum()
            
            full_sum_cols = sum_cols + ['Number of customers', 'Active Customers']
            total_data = {c: total_values[c] for c in sum_cols}
            total_data['Type of product'] = 'TOTAL'
            total_data['Kind of fruit'] = ''
            total_data['Number of customers'] = global_unique_cust
            total_data['Active Customers'] = global_active_cust
            
            total_row = pd.DataFrame([total_data])
            total_row = total_row[cols_order]
            
            st.dataframe(
                total_row.style.format("{:,.0f}", subset=full_sum_cols).apply(highlight_total, subset=['Total']),
                use_container_width=True,
                hide_index=True
            )

        else:
            # --- A. Product Level (Default) ---
            
            region_pivot = df_launch.pivot_table(index=['Type of product', 'Kind of fruit', 'Name of product'], 
                                                    columns='Region', 
                                                    values='Sold', 
                                                    aggfunc='sum', 
                                                    fill_value=0).reset_index()
            
            region_cols = [c for c in region_pivot.columns if c not in ['Type of product', 'Kind of fruit', 'Name of product']]
            
            region_pivot['Total'] = region_pivot[region_cols].sum(axis=1)
            
            final_table = region_pivot.sort_values('Total', ascending=False).reset_index(drop=True)
            
            # Calculate Total Row
            sum_cols = region_cols + ['Total']
            total_values = final_table[sum_cols].sum()
            
            # Reconstruct Total Row to match
            cols_display = ['Type of product', 'Kind of fruit', 'Name of product'] + sorted(region_cols) + ['Total']
            final_table = final_table[cols_display]
            
            total_row_disp = pd.DataFrame(columns=cols_display)
            total_row_disp.loc[0, 'Type of product'] = 'TOTAL'
            for c in sum_cols:
                total_row_disp.loc[0, c] = total_values[c]
            total_row_disp = total_row_disp.fillna('')

            numeric_cols = region_cols + ['Total']

            st.dataframe(
                final_table.style.format("{:,.0f}", subset=numeric_cols).apply(highlight_total, subset=['Total']),
                column_config={
                    "Type of product": "Type",
                    "Kind of fruit": "Kind",
                    "Name of product": "Product",
                },
                use_container_width=True,
                hide_index=True
            )     
            
            st.dataframe(
                total_row_disp.style.format("{:,.0f}", subset=sum_cols).apply(highlight_total, subset=['Total']),
                use_container_width=True,
                hide_index=True
            )          
        # --- 2. Customer List Expander ---
        with st.expander("View Customer Details for Launched Products"):
            if df_launch.empty:
                st.info("No data available.")
            else:
                # Create Short Label
                df_launch['Prod_Label'] = df_launch['Type of product'] + " - " + df_launch['Kind of fruit']
                
                # Identify Top 10 Products (Labels) by Volume
                top_prod_labels = df_launch.groupby('Prod_Label')['Sold'].sum().sort_values(ascending=False).head(10).index.tolist()
                
                # Filter for Top 10
                df_launch_sub_cust = df_launch[df_launch['Prod_Label'].isin(top_prod_labels)].copy()
                
                # --- Dynamic Logic: Split by Year if few products ---
                unique_years_cust = df_launch_sub_cust['Year'].unique()
                if len(top_prod_labels) < 5 and len(unique_years_cust) > 1:
                    df_launch_sub_cust['Prod_Label'] = df_launch_sub_cust['Prod_Label'] + " (" + df_launch_sub_cust['Year'].astype(str) + ")"
                
                # Pivot
                cust_matrix = df_launch_sub_cust.pivot_table(
                    index=['Region', 'Name of client'], 
                    columns='Prod_Label', 
                    values='Sold', 
                    aggfunc='sum', 
                    fill_value=0
                )
                
                cust_matrix['Total'] = cust_matrix.sum(axis=1)
                cust_matrix = cust_matrix.sort_values('Total', ascending=False)
                
                # Add Total Row (Grand Total)
                grand_total = cust_matrix.sum()
                total_row_df = pd.DataFrame([grand_total], columns=cust_matrix.columns)
                total_row_df.index = pd.MultiIndex.from_tuples([('TOTAL', '')], names=['Region', 'Name of client'])
                cust_matrix = pd.concat([total_row_df, cust_matrix])
                
                st.dataframe(
                    cust_matrix.style.format("{:,.0f}").apply(custom_greens, subset=['Total']),
                    use_container_width=True
                )
        
        st.divider()
        
        # --- 3. Charts ---
        c1, c2 = st.columns(2)
        
        with c1:
            st.subheader("Monthly Sales Trend")
            
            # Local Filters for Trend Chart Only
            with st.expander("Filter Trend Data (Year / Customer)", expanded=False):
                ft_col1, ft_col2 = st.columns(2)
                with ft_col1:
                        # Re-create broad context for Options
                        df_launch_all = df.copy()
                        if sel_types_launch:
                            df_launch_all = df_launch_all[df_launch_all['Type of product'].isin(sel_types_launch)]
                        if sel_kinds_launch:
                            df_launch_all = df_launch_all[df_launch_all['Kind of fruit'].isin(sel_kinds_launch)]

                        avail_years_trend = sorted(df_launch_all['Year'].unique())
                        if len(avail_years_trend) > 1:
                            sel_years_trend = st.multiselect("Select Year:", list(map(int, avail_years_trend)), default=list(map(int, avail_years_trend)), key="trend_filter_year")
                        else:
                            sel_years_trend = list(map(int, avail_years_trend))
                with ft_col2:
                        avail_clients_trend = sorted(df_launch_all['Name of client'].dropna().unique())
                        sel_clients_trend = st.multiselect("Select Customer:", avail_clients_trend, key="trend_filter_client")

            df_trend_src = df_launch.copy()
            
            # Apply Local Filters
            if len(avail_years_trend) > 1 and sel_years_trend:
                df_trend_src = df_trend_src[df_trend_src['Year'].isin(sel_years_trend)]
            if sel_clients_trend:
                df_trend_src = df_trend_src[df_trend_src['Name of client'].isin(sel_clients_trend)]
            
            if df_trend_src.empty:
                st.warning("No data for Trend Chart after filtering.")
            else:
                if sel_clients_trend:
                    trend_options = sorted(df_launch_all[df_launch_all['Name of client'].isin(sel_clients_trend)]['Name of product'].unique())
                else:
                    trend_options = sorted(df_launch_all['Name of product'].unique())
                
                select_all_prods = st.checkbox("Select All Products", key="trend_select_all")
                if select_all_prods:
                    sel_trend_prods = trend_options
                    st.caption("All products selected.")
                else:
                        sel_trend_prods = st.multiselect("Select Products for Trend (Default: All):", options=trend_options, key="trend_filter_product")
                
                color_col = None
                
                # --- Multi-Year Handling ---
                multi_year_trend = (len(df_trend_src['Year'].unique()) > 1)
                df_trend_src['Label'] = df_trend_src['Name of product'] # Default Label
                
                if sel_trend_prods:
                    df_trend_src = df_trend_src[df_trend_src['Name of product'].isin(sel_trend_prods)]
                    
                    if multi_year_trend:
                        df_trend_src['Label'] = df_trend_src['Name of product'] + " (" + df_trend_src['Year'].astype(str) + ")"
                        color_col = 'Label'
                        group_cols = ['Year', 'Month', 'Name of product', 'Label']
                    else:
                        color_col = 'Name of product'
                        group_cols = ['Month', 'Name of product']
                        
                    title_text = "Monthly Traction (Selected)"
                else:
                    # All Products Aggregated
                    if multi_year_trend:
                        df_trend_src['Label'] = df_trend_src['Year'].astype(str)
                        color_col = 'Label'
                        group_cols = ['Year', 'Month', 'Label']
                    else:    
                        group_cols = ['Month']
                    title_text = "Monthly Traction (All Launched)"

                # Grouping
                trend = df_trend_src.groupby(group_cols)['Sold'].sum().reset_index()
                
                # Check column mapping
                if color_col and color_col not in trend.columns:
                     # e.g. if we grouped by Month only
                     color_col = None

                fig_trend = px.line(trend, x='Month', y='Sold', color=color_col, markers=True, title=title_text, text='Sold')
                fig_trend.update_traces(texttemplate='%{text:,.0f}', textposition='top center')
                fig_trend.update_layout(template="plotly_white")
                st.plotly_chart(fig_trend, use_container_width=True)
                
            with c2:
                st.subheader("Regional Distribution")
                # Stacked 100% Column Chart with % Labels
                
                # Determine Main Column based on final_table content
                if 'Name of product' in final_table.columns:
                    main_col = 'Name of product'
                    chart_title_suffix = "Top 15 New Products"
                elif 'Kind of fruit' in final_table.columns:
                    main_col = 'Kind of fruit'
                    chart_title_suffix = "Top 15 Kinds of Fruit"
                else:
                    main_col = 'Type of product'
                    chart_title_suffix = "Product Types"
                
                # Top 15 by Volume for readability
                top_launch = final_table.head(15)[main_col].tolist()
                
                # Filter source data
                df_launch_sub = df_launch[df_launch[main_col].isin(top_launch)].copy()
                
                # Clean names for chart
                if main_col == 'Name of product':
                    df_launch_sub['Short Name'] = df_launch_sub['Name of product'].str.replace('ANDROS PROFESSIONAL', '', case=False).str.strip()
                    df_launch_sub['Short Name'] = df_launch_sub['Short Name'].str.replace(r'\s+', ' ', regex=True)
                else:
                    df_launch_sub['Short Name'] = df_launch_sub[main_col]
                
                # Chart Aggregation (Sum over selected years/regions)
                chart_agg = df_launch_sub.groupby(['Short Name', 'Region'])['Sold'].sum().reset_index()
                
                # Calc Percentage
                chart_agg['Total_Prod'] = chart_agg.groupby('Short Name')['Sold'].transform('sum')
                chart_agg['Pct'] = chart_agg['Sold'] / chart_agg['Total_Prod']
                chart_agg['Label'] = chart_agg['Pct'].apply(lambda x: f"{x:.0%}" if x > 0.05 else "") # Hide small labels
                
                fig_stack = px.bar(
                    chart_agg,
                    x='Short Name',
                    y='Sold',
                    color='Region',
                    title=f"Regional Mix ({chart_title_suffix})",
                    text='Label'
                )
                fig_stack.update_layout(template="plotly_white", barnorm='percent', yaxis_title="% Volume", xaxis_title=main_col)
                st.plotly_chart(fig_stack, use_container_width=True)
</file>

<file path="src/tabs/vietnam_focus.py">
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px

def render_vietnam_focus(df, df_curr, df_prev, has_prev_year, current_year_val):
    st.subheader("üáªüá≥ Focus TOP High & Less Performance in Local Vietnam")
    
    # Filter for Vietnam
    # Try to find 'Country' column. If not exists, check Region names?
    # User dataset likely has 'Country'.
    if 'Country' in df.columns:
        # Check values - User confirmed 'Viet Nam'
        # Using 'Viet' to be safe for both 'Vietnam' and 'Viet Nam'
        vn_mask_curr = df_curr['Country'].str.contains('Viet', case=False, na=False)
        vn_mask_prev = df_prev['Country'].str.contains('Viet', case=False, na=False) if not df_prev.empty else pd.Series([False]*len(df_prev))
        
        df_vn_curr = df_curr[vn_mask_curr]
        df_vn_prev = df_prev[vn_mask_prev] if not df_prev.empty else pd.DataFrame(columns=df_curr.columns)
        
        # If empty but Region has Vietnam?
        if df_vn_curr.empty:
            # Fallback to Region check
            vn_mask_curr = df_curr['Region'].str.contains('Viet', case=False, na=False)
            df_vn_curr = df_curr[vn_mask_curr]
            if not df_prev.empty:
                    vn_mask_prev = df_prev['Region'].str.contains('Viet', case=False, na=False)
                    df_vn_prev = df_prev[vn_mask_prev]
    else:
        st.warning("Column 'Country' not found. Creating focus based on available data.")
        df_vn_curr = df_curr
        df_vn_prev = df_prev

    if df_vn_curr.empty:
        st.info("No data found for 'Viet Nam' in the current selection.")
    else:
        # Helper to Render Category Focus
        def render_category_focus(cat_name, filter_keywords):
            st.markdown(f"#### üè∑Ô∏è {cat_name} Performance (Top 10)")
            
            # Filter Category using Regex OR
            # join keywords with |
            pattern = '|'.join([k.strip() for k in filter_keywords])
            
            mask_c = df_vn_curr['Type of product'].str.contains(pattern, case=False, na=False)
            mask_p = df_vn_prev['Type of product'].str.contains(pattern, case=False, na=False) if not df_vn_prev.empty else pd.Series([False]*len(df_vn_prev))
            
            d_c = df_vn_curr[mask_c]
            d_p = df_vn_prev[mask_p] if not df_vn_prev.empty else pd.DataFrame()
            
            if d_c.empty:
                st.write(f"No data found for {cat_name} (Keywords: {filter_keywords}).")
                return
            
            # Group by Name of Product
            top_c = d_c.groupby('Name of product')['Sold'].sum().reset_index().rename(columns={'Sold': 'Vol_Curr'})
            
            # 2024 (Prev)
            if not d_p.empty:
                top_p = d_p.groupby('Name of product')['Sold'].sum().reset_index().rename(columns={'Sold': 'Vol_Prev'})
            else:
                top_p = pd.DataFrame(columns=['Name of product', 'Vol_Prev'])
            
            # Sort Top 10 by Current Volume
            top_c = top_c.sort_values('Vol_Curr', ascending=False)
            
            top_10_names = top_c.head(10)['Name of product'].tolist()
            
            merged = pd.merge(top_c[top_c['Name of product'].isin(top_10_names)], top_p, on='Name of product', how='left').fillna(0)
            
            # Calc Delta
            merged['Delta %'] = ((merged['Vol_Curr'] - merged['Vol_Prev']) / merged['Vol_Prev']).replace([np.inf, -np.inf], 0).fillna(0)
            
            # Handle New
            new_mask = (merged['Vol_Prev'] == 0) & (merged['Vol_Curr'] > 0)
            merged.loc[new_mask, 'Delta %'] = 1.0
            
            # Sort descending volume 
            merged = merged.sort_values('Vol_Curr', ascending=False)
            
            # Table
            def color_delta_simple(val):
                color = '#d4edda' if val > 0 else '#f8d7da' if val < 0 else ''
                return f'background-color: {color}; color: black'

            # Define d_top10 here to be available for both Chart and Insights
            d_top10 = d_c[d_c['Name of product'].isin(top_10_names)].copy()
            d_top10['Short Name'] = d_top10['Name of product'].str.replace('ANDROS PROFESSIONAL', '', case=False).str.strip()
            d_top10['Short Name'] = d_top10['Short Name'].str.replace(r'\s+', ' ', regex=True)

            c_table, c_chart = st.columns([1, 1])
            
            with c_table:
                st.caption("Top 10 Comparison")
                st.dataframe(
                    merged.style.format({
                        "Vol_Curr": "{:,.0f}",
                        "Vol_Prev": "{:,.0f}",
                        "Delta %": "{:+.1%}"
                    }).map(color_delta_simple, subset=['Delta %']),
                    column_config={
                        "Name of product": "Product Name",
                        "Vol_Curr": f"Vol {current_year_val}",
                        "Vol_Prev": f"Vol {current_year_val - 1}" if has_prev_year else "Vol Prev",
                        "Delta %": "% Change"
                    },
                    use_container_width=True,
                    hide_index=True
                )
            
            with c_chart:
                st.caption("Regional Breakdown (Top 10)")
                
                # Macro Region Mapping
                def map_region(r):
                    r_u = r.upper()
                    if 'SOUTH' in r_u: return 'South'
                    if 'NORTH' in r_u: return 'North'
                    if 'CENTER' in r_u or 'CENTRAL' in r_u: return 'Center'
                    return 'Other'
                
                d_top10['Macro Region'] = d_top10['Region'].apply(map_region)
                
                # Group by Product and Macro Region for the chart
                d_chart_agg = d_top10.groupby(['Name of product', 'Macro Region'])['Sold'].sum().reset_index()
                
                # Define Colors: South=Green, North=Blue, Center=Orange
                region_colors = {
                    'South': '#2ca02c',  # Green
                    'North': '#1f77b4',  # Blue
                    'Center': '#ff7f0e', # Orange
                    'Other': '#7f7f7f'   # Grey
                }

                # Stacked 100% chart
                fig_stack = px.bar(
                    d_chart_agg, 
                    x='Name of product', 
                    y='Sold', 
                    color='Macro Region',
                    title=f"Regional Mix (100% Stacked)",
                    barmode='relative',
                    text_auto='.0f',
                    color_discrete_map=region_colors,
                    category_orders={"Macro Region": ["South", "North", "Center", "Other"]}
                )
                fig_stack.update_layout(
                    yaxis_title="% Volume", 
                    xaxis_title="Product", 
                    template="plotly_white", 
                    barnorm='percent',
                    font=dict(size=10), # Reduce global font size
                    xaxis=dict(tickfont=dict(size=9)), # Smaller x-axis labels
                    uniformtext_minsize=8, uniformtext_mode='hide'
                )
                st.plotly_chart(fig_stack, use_container_width=True)
        
            # --- Automated Regional Insights ---
            if not d_top10.empty and 'Kind of fruit' in d_top10.columns:
                interest_df = d_top10.groupby(['Kind of fruit', 'Macro Region'])['Sold'].sum().reset_index()
                
                # Pivot to find max region per fruit
                pivot_interest = interest_df.pivot(index='Kind of fruit', columns='Macro Region', values='Sold').fillna(0)
                
                # Calculate mapped preferences
                preferences = []
                for fruit in pivot_interest.index:
                    vols = pivot_interest.loc[fruit]
                    total = vols.sum()
                    if total == 0: continue
                    
                    winner = vols.idxmax()
                    pct = vols[winner] / total
                    
                    preferences.append((fruit, winner, pct))
                
                # Group by Region to construct sentence
                region_fruits = {}
                for fruit, region, pct in preferences:
                    if region not in region_fruits: region_fruits[region] = []
                    region_fruits[region].append(f"{fruit} ({pct:.0%})")
                
                if region_fruits:
                    insight_lines = []
                    for reg, fruits in region_fruits.items():
                        if reg == 'Other': continue
                        fruit_list = ", ".join(fruits)
                        insight_lines.append(f"- **{reg}**: Drivers include {fruit_list}.")
                    
                    st.info(f"üí° **Regional Interest Insights ({cat_name}):**\n\n" + "\n".join(insight_lines))
                else:
                    st.info(f"No clear regional dominance found for top {cat_name} items.")
            else:
                    pass
        
        # Categories Definition
        bev_types = ['Chunky', 'Fruit Mix', 'Jelly Top Up', 'Syrup']
        bakery_types = ['Frozen Puree', 'Fruit Filling', 'Frozen Fruit', 'Top&Fill', 'Top & Fill', 'Chocofill'] 
        
        # Render Sections
        render_category_focus("Beverage", bev_types)
        st.divider()
        render_category_focus("Bakery", bakery_types)
</file>

<file path="src/analysis.py">
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
from src.utils import DEFAULT_DATE_COL

def compute_top_level_kpis(df: pd.DataFrame) -> dict:
    """Compute the top-level KPIs described in the design.
    Returns a dict of simple scalars and series.
    """
    kpis = {}
    total_revenue = df['Sold'].sum()
    total_kg = df['Quantity (KG)'].sum()
    active_clients = df['Name of client'].nunique()

    # average revenue per client
    rev_per_client = df.groupby('Name of client')['Sold'].sum().mean()

    # Monthly aggregated series for growth calculations
    monthly = df.groupby(pd.Grouper(key=DEFAULT_DATE_COL, freq='M')).agg({'Sold': 'sum'}).sort_index()

    # YoY growth (last full year vs previous)
    years = df['Year'].dropna().unique()
    years = sorted([int(y) for y in years if not pd.isna(y)])
    yoy = None
    if len(years) >= 2:
        last_year = years[-1]
        prev_year = years[-2]
        last_sum = df.loc[df['Year'] == last_year, 'Sold'].sum()
        prev_sum = df.loc[df['Year'] == prev_year, 'Sold'].sum()
        yoy = (last_sum - prev_sum) / prev_sum if prev_sum != 0 else np.nan

    # MoM growth (compare last month vs previous month)
    mom = None
    if len(monthly) >= 2:
        mom = (monthly['Sold'].iloc[-1] - monthly['Sold'].iloc[-2]) / (monthly['Sold'].iloc[-2] if monthly['Sold'].iloc[-2] != 0 else np.nan)

    # New / churned clients
    last_date = df[DEFAULT_DATE_COL].max()
    cutoff_new = last_date - pd.DateOffset(months=12)
    clients_last_year = set(df.loc[df[DEFAULT_DATE_COL] >= cutoff_new, 'Name of client'].unique())
    all_clients = set(df['Name of client'].unique())
    new_clients = clients_last_year  # naive: clients who appear in last 12 months (could refine)

    # churn: clients with no orders in last 3 months
    cutoff_churn = last_date - pd.DateOffset(months=3)
    active_recent = set(df.loc[df[DEFAULT_DATE_COL] >= cutoff_churn, 'Name of client'].unique())
    churned_clients = list(all_clients - active_recent)

    # Top product / fruit
    top_product = df.groupby('Name of product')['Sold'].sum().sort_values(ascending=False).head(1)
    top_fruit = df.groupby('Kind of fruit')['Sold'].sum().sort_values(ascending=False).head(1)

    kpis.update({
        'total_revenue': float(total_revenue),
        'total_kg': float(total_kg),
        'active_clients': int(active_clients),
        'avg_revenue_per_client': float(rev_per_client),
        'monthly_series': monthly.reset_index(),
        'yoy_growth': float(yoy) if yoy is not None else None,
        'mom_growth': float(mom) if mom is not None else None,
        'new_clients_last_12m_count': len(new_clients),
        'churned_clients_count': len(churned_clients),
        'top_product': dict(top_product.head(1)) if not top_product.empty else {},
        'top_fruit': dict(top_fruit.head(1)) if not top_fruit.empty else {}
    })

    return kpis


def compute_client_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """Return dataframe aggregated by client with key metrics: revenue, kg, orders, freq, recency, LTV (simple), RFM score.
    """
    now = df[DEFAULT_DATE_COL].max() + pd.DateOffset(days=1)
    client = df.groupby('Name of client').agg(
        revenue=('Sold', 'sum'),
        kg=('Quantity (KG)', 'sum'),
        orders=('Sold', 'count'),
        last_order=(DEFAULT_DATE_COL, 'max'),
        first_order=(DEFAULT_DATE_COL, 'min')
    ).reset_index()

    client['recency_days'] = (now - client['last_order']).dt.days
    client['frequency'] = client['orders']
    client['monetary'] = client['revenue']

    # Simple RFM scoring: quantiles
    client['r_score'] = pd.qcut(client['recency_days'].rank(method='first'), 5, labels=range(5, 0, -1)).astype(int)
    client['f_score'] = pd.qcut(client['frequency'].rank(method='first'), 5, labels=range(1, 6)).astype(int)
    client['m_score'] = pd.qcut(client['monetary'].rank(method='first'), 5, labels=range(1, 6)).astype(int)
    client['rfm_score'] = client['r_score']*100 + client['f_score']*10 + client['m_score']

    return client.sort_values('revenue', ascending=False)


def compute_product_metrics(df: pd.DataFrame) -> pd.DataFrame:
    prod = df.groupby(['Name of product', 'SKU', 'Kind of fruit', 'Type of product']).agg(
        revenue=('Sold', 'sum'),
        kg=('Quantity (KG)', 'sum'),
        orders=('Sold', 'count')
    ).reset_index()
    prod['price_per_kg'] = prod['revenue'] / prod['kg'].replace({0: np.nan})
    prod = prod.sort_values('revenue', ascending=False)
    return prod


def compute_region_metrics(df: pd.DataFrame) -> pd.DataFrame:
    r = df.groupby(['Region', 'Country']).agg(
        revenue=('Sold', 'sum'),
        kg=('Quantity (KG)', 'sum')
    ).reset_index().sort_values('revenue', ascending=False)
    return r


def compute_rfm_clusters(client_df: pd.DataFrame, n_clusters=4) -> pd.DataFrame:
    features = client_df[['recency_days', 'frequency', 'monetary']].fillna(0)
    # Simple scaling (min-max)
    scaler = MinMaxScaler()
    X = scaler.fit_transform(features)
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    client_df['cluster'] = kmeans.fit_predict(X)
    return client_df
</file>

<file path="src/charts.py">
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from src.utils import DEFAULT_DATE_COL

def fig_top_level(kpis: dict) -> go.Figure:
    monthly = kpis['monthly_series']
    fig = px.line(monthly, x=DEFAULT_DATE_COL, y='Sold', title='Monthly Revenue')
    return fig


def fig_top_products(prod_df: pd.DataFrame, top_n=20) -> go.Figure:
    top = prod_df.head(top_n)
    fig = px.bar(top, x='Name of product', y='revenue', title=f'Top {top_n} Products by Revenue')
    fig.update_layout(xaxis={'categoryorder':'total descending'})
    return fig


def fig_region_map(region_df: pd.DataFrame):
    # If region_df contains country names we can use choropleth; user may need to provide ISO codes
    if 'Country' in region_df.columns:
        agg = region_df.groupby('Country').agg(revenue=('revenue', 'sum')).reset_index()
        try:
            fig = px.choropleth(agg, locations='Country', locationmode='country names', color='revenue', title='Revenue by Country')
            return fig
        except Exception:
            # Fallback: bar chart
            fig = px.bar(agg.sort_values('revenue', ascending=False).head(20), x='Country', y='revenue', title='Revenue by Country (Top 20)')
            return fig
    else:
        return go.Figure()
</file>

<file path="src/data_processing.py">
import pandas as pd
import numpy as np
import datetime as dt
from pathlib import Path
import streamlit as st
import re
from src.utils import DEFAULT_DATE_COL

# Expected columns based on your schema
EXPECTED_COLS = [
    'Year', 'Month', 'Name of client', 'Channel by Sales Person',
    'Region', 'Country', 'Name of product', 'Kind of fruit', 'SKU',
    'Type of product', 'Sold', 'Quantity (KG)'
]

@st.cache_data(show_spinner=False)
def load_data(file_path_or_buffer, csv_fallback=True, nrows=None) -> pd.DataFrame:
    """Load Excel or CSV robustly.
    - file_path_or_buffer: path to .xlsx/.csv OR a file-like object (buffer)
    - nrows: optional for sampling
    Returns full dataframe.
    """
    # Helper to detect extension if it's a file path
    is_path = isinstance(file_path_or_buffer, (str, Path))
    
    if is_path:
        p = Path(file_path_or_buffer)
        if not p.exists():
            raise FileNotFoundError(f"File not found: {file_path_or_buffer}")
        suffix = p.suffix.lower()
    else:
        # It's a buffer (e.g. from streamlit uploader). 
        # We try to guess from the .name attribute if available, else try read_excel then read_csv
        suffix = Path(file_path_or_buffer.name).suffix.lower() if hasattr(file_path_or_buffer, 'name') else ''

    try:
        if suffix == '.csv':
            df = pd.read_csv(file_path_or_buffer, nrows=nrows)
        else:
            # Default to Excel - Read ALL sheets
            dfs = pd.read_excel(file_path_or_buffer, nrows=nrows, engine='openpyxl', sheet_name=None)
            
            # If multiple sheets, concat
            if isinstance(dfs, dict):
                # Filter out empty sheets or metadata sheets if needed
                # For now, just concat all frames
                all_frames = []
                for sheet_name, sheet_df in dfs.items():
                    # Add sheet name as column for debugging/filtering if useful
                    # sheet_df['Sheet'] = sheet_name 
                    all_frames.append(sheet_df)
                df = pd.concat(all_frames, ignore_index=True)
            else:
                df = dfs
                
    except Exception as e:
        # Fallback logic could go here, for now just re-raise
        raise ValueError(f"Could not load data. Error: {e}")

    # Standardize column names by stripping
    df.columns = [str(c).strip() for c in df.columns]
    return df


@st.cache_data(show_spinner=False)
def clean_data(df: pd.DataFrame) -> pd.DataFrame:
    """Clean & canonicalize the incoming dataframe. Returns cleaned df.
    Steps:
      - Ensure expected columns exist (attempt fuzzy match)
      - Cast types
      - Create a synthetic date column: Year/Month -> 1st of month
      - Fill NAs with sensible defaults
      - Standardize text columns
    """
    df = df.copy()

    # --- fuzzy column mapping if user has slightly different headers
    # Priority mapping for known variations
    known_mappings = {
        'Sold quantity (KG)': 'Quantity (KG)',
        'Sales': 'Sold',
        'Revenue': 'Sold',
        'Amount': 'Sold',
        'Channel': 'Channel by Sales Person'
    }
    df = df.rename(columns=known_mappings)

    col_map = {}
    cols = list(df.columns)
    for expected in EXPECTED_COLS:
        for c in cols:
            # Exact match already handled by rename or existence
            if c in df.columns:
                continue
            # Fuzzy match
            if c.lower().replace(' ', '') == expected.lower().replace(' ', ''):
                col_map[c] = expected
                break
    if col_map:
        df = df.rename(columns=col_map)

    # Ensure all expected exist; if not, create placeholders
    for c in EXPECTED_COLS:
        if c not in df.columns:
            # If 'Sold' is missing, likely no revenue column. Warn or just 0.
            # print(f"Warning: Column '{c}' not found. Filling with defaults.") 
            df[c] = pd.NA

    # Cast numeric columns
    df['Quantity (KG)'] = pd.to_numeric(df['Quantity (KG)'], errors='coerce').fillna(0.0)
    # Use Quantity as Sold (Revenue) as per user request
    df['Sold'] = df['Quantity (KG)']

    # Year/Month to integers
    df['Year'] = pd.to_numeric(df['Year'], errors='coerce')
    # Clean Month column before coercion
    def clean_month_val(x):
        if isinstance(x, str):
            digits = re.findall(r'\d+', x)
            return int(digits[0]) if digits else x
        return x
        
    df['Month'] = df['Month'].apply(clean_month_val)
    df['Month'] = pd.to_numeric(df['Month'], errors='coerce')

    # Fill missing client names
    df['Name of client'] = df['Name of client'].fillna('Unknown client').astype(str)

    # Standardize text columns: strip, title-case where appropriate
    text_cols = ['Channel by Sales Person', 'Region', 'Country', 'Kind of fruit', 'SKU', 'Type of product']
    for c in text_cols:
        if c in df.columns:
            df[c] = df[c].fillna('Unknown').astype(str).str.strip()
            # Normalize Channel to Title Case to merge "Retail" vs "retail"
            if c == 'Channel by Sales Person':
                df[c] = df[c].str.title()
            
    if 'Name of product' in df.columns:
        # User request: remove 'ANDROS PROFESSIONAL' globally
        df['Name of product'] = df['Name of product'].fillna('Unknown').astype(str).str.replace('ANDROS PROFESSIONAL', '', case=False).str.strip()
        # Clean extra spaces
        df['Name of product'] = df['Name of product'].str.replace(r'\s+', ' ', regex=True)

    # Synthetic date column 1st day of month (useful for time-series grouping)
    def make_date(r):
        try:
            y = int(r['Year'])
            m = r['Month']
            
            # Handle string months like 'R1', 'M01', etc.
            if isinstance(m, str):
                # Extract digits
                digits = re.findall(r'\d+', m)
                if digits:
                    m = int(digits[0])
                else:
                    # Fallback to 1 if no digits found
                    m = 1
            
            # Ensure m is within 1-12 range logic if needed, or just standard date
            # If m is 0 or >12, date() will raise ValueError, so we catch it
            return dt.date(y, m, 1)
        except Exception:
            return pd.NaT

    df[DEFAULT_DATE_COL] = df.apply(make_date, axis=1)
    df[DEFAULT_DATE_COL] = pd.to_datetime(df[DEFAULT_DATE_COL])

    # Drop rows without date
    df = df[~df[DEFAULT_DATE_COL].isna()].reset_index(drop=True)

    return df
</file>

<file path="src/ui_helpers.py">
import streamlit as st

def apply_custom_styles():
    st.markdown("""
    <style>
    /* Metric Cards */
    div[data-testid="stMetric"] {
        background: linear-gradient(135deg, #2E3192 0%, #1BFFFF 100%); /* Dark Blue to Cyan Gradient */
        border: none;
        padding: 15px 25px;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        color: white;
    }
    div[data-testid="stMetricLabel"] {
        font-size: 14px;
        color: #f0f0f0; /* Light text for dark bg */
        font-weight: 500;
    }
    div[data-testid="stMetricValue"] {
        font-size: 24px;
        font-weight: 700;
        color: #ffffff;
    }
    div[data-testid="stMetricDelta"] {
        font-size: 14px;
        color: #e0e0e0; /* Lighter delta */
        background-color: rgba(255,255,255,0.2);
        padding: 2px 8px;
        border-radius: 4px;
    }
    
    /* Tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 20px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: transparent;
        border-radius: 8px;
        color: #555;
        font-weight: 600;
        padding: 0 20px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #F0F4FF;
        color: #1E90FF;
    }
    </style>
    """, unsafe_allow_html=True)

def checkbox_filter(label, options, key_prefix, default_selected=None, expanded=False):
    """Custom multi-select using checkboxes inside an expander."""
    selected = []
    with st.sidebar.expander(label, expanded=expanded):
        # Select All toggle could be added here, but sticking to simple list for now
        
        for val in options:
            # Create a unique key for each checkbox
            k = f"{key_prefix}_{val}"
            # Determine default value
            is_checked = True
            if default_selected is not None:
                    is_checked = (val in default_selected)
            
            if st.checkbox(str(val), value=is_checked, key=k):
                selected.append(val)
    return selected
</file>

<file path="src/utils.py">
import os
import json
import pandas as pd
import numpy as np

# Optional: OpenAI for AI insights
try:
    import openai
    OPENAI_AVAILABLE = True
except Exception:
    OPENAI_AVAILABLE = False

DEFAULT_DATE_COL = 'date__ym'  # synthetic date column

def filter_by_date(df: pd.DataFrame, years: list, months: list) -> pd.DataFrame:
    """Filter DF by list of years and optional list of months."""
    mask = df['Year'].isin(years)
    if months:
        # Check if 'Month' column is numeric or string match
        # If months are selected as names (Jan, Feb...), map them or use numbers if input is numbers
        mask &= df['Month'].isin(months)
    return df.loc[mask]

def calculate_growth(current_val, prev_val):
    if prev_val == 0 or pd.isna(prev_val):
        return None
    return (current_val - prev_val) / prev_val

def ai_insights_summary(kpis: dict, top_clients_df: pd.DataFrame, top_products_df: pd.DataFrame, openai_api_key: str = None) -> str:
    """Generate short insights. If OpenAI key provided and openai package installed, will call the API.
    Otherwise returns a template summary you can use.
    """
    summary = []
    summary.append(f"Total revenue: {kpis.get('total_revenue'):,}")
    summary.append(f"Total KG sold: {kpis.get('total_kg'):,}")
    if kpis.get('yoy_growth') is not None:
        summary.append(f"YoY growth: {kpis.get('yoy_growth'):.2%}")
    if kpis.get('mom_growth') is not None:
        summary.append(f"MoM growth: {kpis.get('mom_growth'):.2%}")

    # top product
    if kpis.get('top_product'):
        tp = list(kpis['top_product'].items())[0]
        summary.append(f"Top product: {tp[0]} ({tp[1]:,.2f} revenue)")

    # basic templated insights
    templated = '\n'.join(summary)

    if OPENAI_AVAILABLE and openai_api_key:
        openai.api_key = openai_api_key
        prompt = f"You are an expert data analyst. Summarize the following KPI facts and produce 5 action-oriented insights and 3 risks:\n{templated}\nTop 5 clients by revenue:\n{top_clients_df.head(5).to_dict(orient='records')}\nTop 5 products:\n{top_products_df.head(5).to_dict(orient='records')}"
        try:
            resp = openai.Completion.create(
                model='gpt-4o-mini',
                prompt=prompt,
                max_tokens=400,
                temperature=0.2
            )
            return resp.choices[0].text.strip()
        except Exception as e:
            return templated + "\n\nNOTE: OpenAI call failed: " + str(e)
    else:
        # Return a readable insight template
        insight_text = templated + "\n\nSuggested insights (template):\n1. Focus on top 10 clients who contribute majority revenue; run promotions to retain them.\n2. Investigate underperforming regions and reallocate sales effort.\n3. Check seasonality for top fruit types and align inventory.\n4. Evaluate Channel performance and prioritize high AOV channels.\n5. Build RFM segments for targeted campaigns."
        return insight_text

def export_reports(out_dir: str, kpis: dict, client_df: pd.DataFrame, prod_df: pd.DataFrame, region_df: pd.DataFrame):
    os.makedirs(out_dir, exist_ok=True)
    # Save main KPIs as JSON
    with open(os.path.join(out_dir, 'kpis.json'), 'w') as f:
        json.dump({k:v if not hasattr(v, 'to_dict') else None for k,v in kpis.items()}, f, default=str)

    client_df.to_csv(os.path.join(out_dir, 'clients.csv'), index=False)
    prod_df.to_csv(os.path.join(out_dir, 'products.csv'), index=False)
    region_df.to_csv(os.path.join(out_dir, 'regions.csv'), index=False)
    if 'monthly_series' in kpis:
        kpis['monthly_series'].to_csv(os.path.join(out_dir, 'monthly_series.csv'), index=False)

    print(f"Reports exported to {out_dir}")
</file>

<file path=".gitignore">
venv/
__pycache__/
.DS_Store
*.xlsx
</file>

<file path="debug_active.py">
import pandas as pd
import datetime as dt

# Load data utilizing the same logic as dashboard.py (simplified)
def load_and_clean():
    try:
        df = pd.read_excel('data.xlsx', engine='openpyxl')
        
        # Renaissance of clean_data logic
        df['Quantity (KG)'] = pd.to_numeric(df['Quantity (KG)'], errors='coerce').fillna(0.0)
        df['Sold'] = df['Quantity (KG)'] # Logic from dashboard.py

        # Date Logic
        # Assuming Year/Month columns exist
        def make_date(r):
            try:
                y = int(r['Year'])
                m = r['Month']
                if isinstance(m, str):
                    import re
                    digits = re.findall(r'\d+', m)
                    m = int(digits[0]) if digits else 1
                return dt.date(y, m, 1)
            except:
                return pd.NaT

        df['date__ym'] = df.apply(make_date, axis=1)
        df['date__ym'] = pd.to_datetime(df['date__ym'])
        df = df[~df['date__ym'].isna()]
        return df
    except Exception as e:
        print(f"Error loading: {e}")
        return pd.DataFrame()

df = load_and_clean()

if not df.empty:
    max_date = df['date__ym'].max()
    print(f"Max Date in Data: {max_date}")
    
    cutoff_6m = max_date - pd.DateOffset(months=6)
    print(f"Cutoff 6 months: {cutoff_6m}")
    
    # Check distinct clients in last 6 months
    df_6m = df[df['date__ym'] >= cutoff_6m]
    print(f"Rows in last 6 months: {len(df_6m)}")
    
    # Group by Product + Client
    print("\n--- Sample Active Analysis ---")
    grp = df_6m.groupby(['Name of product', 'Name of client']).size().reset_index(name='OrderCount')
    
    # Filter >= 2
    active = grp[grp['OrderCount'] >= 2]
    
    print(f"Total pairs (Product, Client) in last 6m: {len(grp)}")
    print(f"Active pairs (>=2 orders): {len(active)}")
    
    if len(active) > 0:
        print("Sample Active Calculation:")
        print(active.head(5))
        
    # Check specific case if possible. Look for a product with high volume but 0 active?
    # We can just list top 5 products by row count in last 6m
    print("\nTop 5 Products by Activity (Row Count in last 6m):")
    top_prod = df_6m['Name of product'].value_counts().head(5)
    print(top_prod)
    
else:
    print("DataFrame empty.")
</file>

<file path="inspect_data.py">
import pandas as pd
import sys

try:
    df = pd.read_excel('data.xlsx')
    print("Columns:", df.columns.tolist())
    print("\nFirst 3 rows:")
    print(df.head(3).to_string())
    print("\nData Types:")
    print(df.dtypes)
except Exception as e:
    print(f"Error reading file: {e}")
</file>

<file path="requirements.txt">
pandas
openpyxl
plotly
streamlit
scikit-learn
numpy
</file>

<file path="dashboard.py">
r"""
Sales Dashboard Project
Single-file distribution containing helper functions, KPI generation, Plotly charts, Streamlit app, and AI insight generator.

HOW TO USE (ENGLISH):
1. Create a virtualenv and install requirements:
   python -m venv venv
   source venv/bin/activate   # or venv\Scripts\activate on Windows
   pip install -r requirements.txt

2. Place your Excel file next to this script and set FILE_PATH variable or pass as CLI arg.
   If Excel is too large, save as CSV and use that instead (faster for pandas).

3. Run locally:
   # Quick KPI run (prints & saves csv reports)
   python dashboard.py --file sales.xlsx --mode kpis

   # Run Streamlit dashboard
   streamlit run dashboard.py -- --file sales.xlsx --mode streamlit
"""

import argparse
import sys
import datetime as dt
import streamlit as st
import pandas as pd

# Import modules
from src.data_processing import load_data, clean_data
from src.analysis import (
    compute_top_level_kpis,
    compute_client_metrics,
    compute_product_metrics,
    compute_region_metrics,
    compute_rfm_clusters
)
from src.utils import (
    ai_insights_summary,
    export_reports,
    filter_by_date
)
from src.ui_helpers import apply_custom_styles, checkbox_filter

# Import Tab Renderers
from src.tabs.executive_overview import render_executive_overview
from src.tabs.product_intelligence import render_product_intelligence
from src.tabs.customer_market import render_customer_market
from src.tabs.growth_insights import render_growth_insights
from src.tabs.vietnam_focus import render_vietnam_focus
from src.tabs.product_launching import render_product_launching

# -------------------------
# Streamlit App
# -------------------------

def streamlit_app(df: pd.DataFrame = None):
    st.set_page_config(layout='wide', page_title='Professional Sales Dashboard')

    # --- CSS: Professional Theme ---
    apply_custom_styles()

    # If no dataframe passed (e.g. not loaded via CLI arg), show uploader
    raw_cols = []
    if df is None:
        st.info("No file provided via CLI. Please upload your Sales Data (Excel or CSV).")
        uploaded_file = st.file_uploader("Upload Sales Data", type=['xlsx', 'xls', 'csv'])
        if uploaded_file is not None:
            try:
                # Load Raw
                df_raw = load_data(uploaded_file)
                raw_cols = list(df_raw.columns)
                
                # Check for Multiple Sheets? read_excel reads 1st by default.
                
                # Clean
                df = clean_data(df_raw)
            except Exception as e:
                st.error(f"Error loading file: {e}")
                return
        else:
            st.stop()
    else:
        # CLI usage, we don't have raw cols easily unless we change main(). 
        pass

    # --- Sidebar: Global Controls ---
    st.sidebar.title("üìä Control Panel")
    
    # Debug Info
    with st.sidebar.expander("üõ† Data Debug Info"):
        st.write(f"**Rows loaded (Cleaned):** {len(df)}")
        # st.write(f"**Raw Columns (Before Clean):** {raw_cols}") # raw_cols might be empty if CLI
        st.write(f"**Cleaned Columns:** {list(df.columns)}")
        st.write("**Unique Years:**", df['Year'].unique())
        st.write("**Unique Regions:**", df['Region'].unique())
        st.write("First 3 rows (Cleaned):")
        st.dataframe(df.head(3))
    
    # Year Filter (Checkbox)
    years = sorted(df['Year'].dropna().astype(int).unique())
    if not years:
        st.error("No valid Years found in data!")
        st.stop()
        
    # Default to Current System Year if available, else latest year
    current_year_sys = dt.datetime.now().year
    default_year_list = [current_year_sys] if current_year_sys in years else ([years[-1]] if years else [])
    
    # User Request: Default expand Years and Regions
    selected_years = checkbox_filter('Select Years', years, key_prefix="year_filter", default_selected=default_year_list, expanded=True)
    if not selected_years:
        st.warning("Please select at least one year.")
        st.stop()
    
    # Month Filter (Checkbox)
    all_months = sorted(df['Month'].dropna().unique())
    selected_months = checkbox_filter('Select Months', all_months, key_prefix="month_filter")
    
    if not selected_months:
         st.warning("Please select at least one month.")
         st.stop() 
    
    # Region Filter (Checkbox)
    unique_regions = sorted(df['Region'].dropna().unique().tolist())
    selected_regions = checkbox_filter('Select Regions', unique_regions, key_prefix="region_filter", expanded=True)
    if not selected_regions:
         st.warning("Please select at least one region.")
         st.stop()
         
    # Channel Filter (Checkbox)
    selected_channels = []
    if 'Channel by Sales Person' in df.columns:
        unique_channels = sorted(df['Channel by Sales Person'].dropna().unique().tolist())
        selected_channels = checkbox_filter('Select Channels', unique_channels, key_prefix="channel_filter")
    else:
        pass
        
    # Country Filter (Checkbox)
    selected_countries = []
    if 'Country' in df.columns:
        unique_countries = sorted(df['Country'].dropna().unique().tolist())
        selected_countries = checkbox_filter('Select Country', unique_countries, key_prefix="country_filter")
    
    # --- Data Filtering ---
    # 1. Current Period Data
    df_curr = filter_by_date(df, selected_years, selected_months)
    df_curr = df_curr[df_curr['Region'].isin(selected_regions)]
    
    # Apply Channel Filter
    if 'Channel by Sales Person' in df.columns and selected_channels:
        df_curr = df_curr[df_curr['Channel by Sales Person'].isin(selected_channels)]
    elif 'Channel by Sales Person' in df.columns and not selected_channels:
        st.warning("Please select at least one Channel.")
        st.stop()
        
    # Apply Country Filter
    if 'Country' in df.columns and selected_countries:
        df_curr = df_curr[df_curr['Country'].isin(selected_countries)]
    elif 'Country' in df.columns and not selected_countries:
        st.warning("Please select at least one Country.")
        st.stop()

    # 2. Comparison Logic (Dynamic)
    # Only enable comparison if EXACTLY ONE year is selected, to avoid ambiguity.
    single_year_mode = (len(selected_years) == 1)
    current_year_val = selected_years[0] if single_year_mode else None
    
    has_prev_year = False
    df_prev = pd.DataFrame()

    if single_year_mode:
        has_prev_year = (current_year_val - 1) in years
        
        if has_prev_year:
            # Standard YoY
            df_prev = filter_by_date(df, [current_year_val - 1], selected_months)
            df_prev = df_prev[df_prev['Region'].isin(selected_regions)]
            
            # Apply Channel Filter
            if 'Channel by Sales Person' in df.columns and selected_channels:
                df_prev = df_prev[df_prev['Channel by Sales Person'].isin(selected_channels)]
                
            # Apply Country Filter
            if 'Country' in df.columns and selected_countries:
                df_prev = df_prev[df_prev['Country'].isin(selected_countries)]
    else:
        # Fallback: MoM (Month-over-Month) or Multi-Year View
        pass

    # --- Main UI ---
    title_text = f"üöÄ Business Performance: {', '.join(map(str, selected_years))}" if len(selected_years) <= 3 else f"üöÄ Business Performance: {len(selected_years)} Years Selected"
    st.title(title_text)
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["üìä Executive Overview", "üì¶ Product Intelligence", "üë• Customer & Market", "üìà Growth & Insights", "üáªüá≥ Vietnam Focus", "üöÄ Product Launching"])

    # === TAB 1: EXECUTIVE OVERVIEW ===
    with tab1:
        render_executive_overview(df_curr, df_prev, selected_years, selected_months, current_year_val, single_year_mode, has_prev_year)

    # === TAB 2: PRODUCT INTELLIGENCE ===
    with tab2:
        render_product_intelligence(df_curr, selected_years)

    # === TAB 3: CUSTOMER & MARKET ===
    with tab3:
        render_customer_market(df, df_curr)

    # === TAB 4: GROWTH & INSIGHTS ===
    with tab4:
        render_growth_insights(df_curr, df_prev, selected_years, selected_months, current_year_val, single_year_mode, has_prev_year, df, selected_regions)

    # === TAB 5: LOCAL VIETNAM FOCUS ===
    with tab5:
        render_vietnam_focus(df, df_curr, df_prev, has_prev_year, current_year_val)

    # === TAB 6: PRODUCT LAUNCHING ===
    with tab6:
        render_product_launching(df, df_curr, df_prev, current_year_val)


# -------------------------
# CLI Entrypoint
# -------------------------

def main():
    parser = argparse.ArgumentParser()
    # Make file optional
    parser.add_argument('--file', type=str, default=None, help='Path to sales.xlsx or sales.csv')
    parser.add_argument('--mode', type=str, default='kpis', choices=['kpis', 'streamlit'], help='mode')
    parser.add_argument('--out', type=str, default='reports_out', help='output folder')
    parser.add_argument('--openai_key', type=str, default=None, help='OpenAI key for AI insights (optional)')
    args, unknown = parser.parse_known_args()

    # Smart default: If no file provided, assume streamlit mode (interactive)
    # This fixes usage: `streamlit run dashboard.py` without args
    if args.file is None and args.mode == 'kpis':
        # Check if user explicitly passed --mode kpis
        if '--mode' not in sys.argv and '-m' not in sys.argv:
             args.mode = 'streamlit'

    # If mode is explicitly kpis, file is required
    if args.mode == 'kpis' and not args.file:
        print("Error: --file argument is required in 'kpis' mode.")
        sys.exit(1)

    df = None
    if args.file:
        df = load_data(args.file)
        df = clean_data(df)

    if args.mode == 'kpis':
        kpis = compute_top_level_kpis(df)
        client_df = compute_client_metrics(df)
        prod_df = compute_product_metrics(df)
        region_df = compute_region_metrics(df)

        # clustering
        client_df = compute_rfm_clusters(client_df)

        # export
        export_reports(args.out, kpis, client_df, prod_df, region_df)

        # print short summary
        print('\n-- TOP KPIS --')
        print(f"Total revenue: {kpis['total_revenue']:,}")
        print(f"Total KG: {kpis['total_kg']:,}")
        if kpis.get('yoy_growth') is not None:
            print(f"YoY growth: {kpis['yoy_growth']:.2%}")
        if args.openai_key:
            print('\nAI Insights:')
            print(ai_insights_summary(kpis, client_df, prod_df, openai_api_key=args.openai_key))

    elif args.mode == 'streamlit':
        # Hand off to streamlit; when streamlit runs it will import and call this script
        streamlit_app(df)


if __name__ == '__main__':
    main()
</file>

</files>
